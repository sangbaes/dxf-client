#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DXF Translation Client (Simplified)
====================================
ë©€í‹° íŒŒì¼ ì—…ë¡œë“œ ì‹œ ê° íŒŒì¼ì„ ë…ë¦½ì ì¸ jobìœ¼ë¡œ ì²˜ë¦¬
ë°°ì¹˜ ê°œë… ì œê±°, ë‹¨ìˆœí•˜ê³  ì•ˆì •ì ì¸ êµ¬ì¡°
"""

import json
import time
import uuid
from io import BytesIO
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Optional, Dict, List

import streamlit as st
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload
from googleapiclient.errors import HttpError
import httplib2
from google_auth_httplib2 import AuthorizedHttp


# =========================
# Config
# =========================
DXF_SHARED_FOLDER_ID = "1qhx_xTGdOusxhV0xN2df4Kc8JTfh3zTd"
SUBFOLDERS = ["INBOX", "DONE", "META"]
MAX_FILE_MB = 200
MAX_FILE_BYTES = MAX_FILE_MB * 1024 * 1024

SEOUL_TZ = timezone(timedelta(hours=9))
SCOPES = ["https://www.googleapis.com/auth/drive"]


# =========================
# Helper Functions
# =========================
def now_seoul_iso() -> str:
    """í˜„ì¬ ì‹œê°„ ISO í¬ë§· (ì„œìš¸ ì‹œê°„ëŒ€)"""
    return datetime.now(SEOUL_TZ).isoformat(timespec="seconds")


def make_job_id(original_name: str) -> str:
    """ê³ ìœ  job_id ìƒì„±: YYYYMMDD_HHMMSS_uuid8_filename"""
    ts = datetime.now(SEOUL_TZ).strftime("%Y%m%d_%H%M%S")
    short_uuid = uuid.uuid4().hex[:8]
    safe_name = "".join(c for c in original_name if c.isalnum() or c in ("-", "_", "."))
    safe_name = safe_name[:40] if safe_name else "file"
    return f"{ts}_{short_uuid}_{safe_name}"


def sanitize_filename(filename: str) -> str:
    """íŒŒì¼ëª… ì •ë¦¬ (ê²½ë¡œ ê³µê²© ë°©ì§€)"""
    return Path(filename).name


def format_bytes(bytes_size: int) -> str:
    """ë°”ì´íŠ¸ë¥¼ ì½ê¸° ì‰¬ìš´ í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.1f}{unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.1f}TB"


# =========================
# Drive API (ì•ˆì •í™”ëœ ë²„ì „)
# =========================
@st.cache_resource(show_spinner=False)
def get_drive_service():
    """Drive API ì„œë¹„ìŠ¤ ìƒì„± (OAuth, timeout ì„¤ì •)"""
    try:
        cfg = st.secrets["drive_oauth"]
        creds = Credentials(
            token=None,
            refresh_token=cfg["refresh_token"],
            token_uri="https://oauth2.googleapis.com/token",
            client_id=cfg["client_id"],
            client_secret=cfg["client_secret"],
            scopes=SCOPES,
        )
        creds.refresh(Request())
        
        # httplib2 timeout ì„¤ì • (ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„±)
        authed_http = AuthorizedHttp(creds, http=httplib2.Http(timeout=30))
        return build("drive", "v3", http=authed_http, cache_discovery=False)
    except Exception as e:
        st.error(f"âŒ Drive API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()


def drive_api_call(func, retries=3, base_delay=1.0):
    """
    Drive API í˜¸ì¶œì„ ì•ˆì •ì ìœ¼ë¡œ ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§)
    
    Args:
        func: ì‹¤í–‰í•  í•¨ìˆ˜ (lambda ë“±)
        retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        base_delay: ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
    
    Returns:
        API í˜¸ì¶œ ê²°ê³¼
    """
    last_error = None
    for attempt in range(retries + 1):
        try:
            return func()
        except (HttpError, OSError, Exception) as e:
            last_error = e
            if attempt >= retries:
                raise
            # Exponential backoff
            delay = base_delay * (2 ** attempt)
            time.sleep(delay)
    raise last_error


def find_or_create_folder(drive, parent_id: str, name: str) -> str:
    """í´ë” ì°¾ê¸° ë˜ëŠ” ìƒì„±"""
    def _find():
        q = (
            f"'{parent_id}' in parents and "
            f"name = '{name}' and "
            "mimeType = 'application/vnd.google-apps.folder' and "
            "trashed = false"
        )
        res = drive.files().list(q=q, fields="files(id,name)").execute()
        return res.get("files", [])
    
    files = drive_api_call(_find)
    if files:
        return files[0]["id"]
    
    # í´ë” ìƒì„±
    def _create():
        metadata = {
            "name": name,
            "mimeType": "application/vnd.google-apps.folder",
            "parents": [parent_id],
        }
        folder = drive.files().create(body=metadata, fields="id").execute()
        return folder["id"]
    
    return drive_api_call(_create)


def get_subfolder_ids(drive):
    """ì„œë¸Œí´ë” ID ê°€ì ¸ì˜¤ê¸° (ìºì‹œ í™œìš©)"""
    if "subfolder_ids" in st.session_state:
        return st.session_state["subfolder_ids"]
    
    ids = {}
    for name in SUBFOLDERS:
        ids[name] = find_or_create_folder(drive, DXF_SHARED_FOLDER_ID, name)
    
    st.session_state["subfolder_ids"] = ids
    return ids


def upload_file_to_inbox(drive, inbox_folder_id: str, filename: str, file_bytes: bytes) -> Dict:
    """
    INBOX í´ë”ì— íŒŒì¼ ì—…ë¡œë“œ (Resumable)
    
    Returns:
        {"id": file_id, "name": filename, "size": bytes}
    """
    media = MediaIoBaseUpload(BytesIO(file_bytes), mimetype="application/dxf", resumable=True)
    metadata = {"name": filename, "parents": [inbox_folder_id]}
    
    def _upload():
        req = drive.files().create(body=metadata, media_body=media, fields="id,name,size")
        resp = None
        while resp is None:
            status, resp = req.next_chunk()
            if status:
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì„ íƒì )
                pass
        return resp
    
    return drive_api_call(_upload, retries=5)


def create_meta_json(drive, meta_folder_id: str, meta_filename: str, payload: Dict):
    """
    META í´ë”ì— JSON íŒŒì¼ ìƒì„±
    
    Note: ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
    """
    # ê¸°ì¡´ íŒŒì¼ ê²€ìƒ‰
    def _find():
        q = (
            f"'{meta_folder_id}' in parents and "
            f"name = '{meta_filename}' and "
            "trashed = false"
        )
        res = drive.files().list(q=q, fields="files(id)").execute()
        return res.get("files", [])
    
    existing = drive_api_call(_find)
    
    data = json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8")
    media = MediaIoBaseUpload(BytesIO(data), mimetype="application/json", resumable=False)
    
    if existing:
        # ì—…ë°ì´íŠ¸
        file_id = existing[0]["id"]
        def _update():
            return drive.files().update(fileId=file_id, media_body=media).execute()
        return drive_api_call(_update)
    else:
        # ìƒì„±
        def _create():
            meta = {"name": meta_filename, "parents": [meta_folder_id]}
            return drive.files().create(body=meta, media_body=media, fields="id").execute()
        return drive_api_call(_create)


def list_recent_jobs(drive, meta_folder_id: str, limit: int = 30):
    """ìµœê·¼ ì‘ì—… ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    def _list():
        q = f"'{meta_folder_id}' in parents and trashed=false"
        res = drive.files().list(
            q=q,
            fields="files(id,name,modifiedTime)",
            orderBy="modifiedTime desc",
            pageSize=limit,
        ).execute()
        files = res.get("files", [])
        return [f for f in files if f["name"].lower().endswith(".json")]
    
    try:
        return drive_api_call(_list)
    except Exception as e:
        st.warning(f"âš ï¸ ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ (ì ì‹œ í›„ ì¬ì‹œë„): {type(e).__name__}")
        return []


def read_meta_json(drive, meta_folder_id: str, meta_filename: str) -> Optional[Dict]:
    """META JSON íŒŒì¼ ì½ê¸°"""
    def _find():
        q = (
            f"'{meta_folder_id}' in parents and "
            f"name = '{meta_filename}' and "
            "trashed = false"
        )
        res = drive.files().list(q=q, fields="files(id)").execute()
        return res.get("files", [])
    
    files = drive_api_call(_find)
    if not files:
        return None
    
    file_id = files[0]["id"]
    
    def _download():
        req = drive.files().get_media(fileId=file_id)
        buf = BytesIO()
        downloader = MediaIoBaseDownload(buf, req)
        done = False
        while not done:
            _, done = downloader.next_chunk()
        buf.seek(0)
        return json.loads(buf.read().decode("utf-8"))
    
    return drive_api_call(_download)


def find_done_file(drive, done_folder_id: str, filename: str):
    """DONE í´ë”ì—ì„œ íŒŒì¼ ì°¾ê¸°"""
    def _find():
        q = (
            f"'{done_folder_id}' in parents and "
            f"name = '{filename}' and "
            "trashed = false"
        )
        res = drive.files().list(q=q, fields="files(id,name,size,modifiedTime)").execute()
        return res.get("files", [])
    
    files = drive_api_call(_find)
    return files[0] if files else None


def download_file_bytes(drive, file_id: str) -> bytes:
    """íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ë°”ì´íŠ¸)"""
    def _download():
        req = drive.files().get_media(fileId=file_id)
        buf = BytesIO()
        downloader = MediaIoBaseDownload(buf, req)
        done = False
        while not done:
            _, done = downloader.next_chunk()
        return buf.getvalue()
    
    return drive_api_call(_download, retries=5)


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="DXF Client", layout="centered")

# Google Analytics
st.components.v1.html(
    """
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-E1LFDTNPVP"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-E1LFDTNPVP');
    </script>
    """,
    height=0,
)

st.title("ğŸ”§ DXF Translation Client")

# ì„¤ëª…
with st.expander("ğŸ“– ì‚¬ìš© ë°©ë²•", expanded=False):
    st.markdown("""
### ì‘ë™ ë°©ì‹
1. **DXF íŒŒì¼ ì—…ë¡œë“œ**: ì—¬ëŸ¬ íŒŒì¼ì„ ì„ íƒ ê°€ëŠ¥ (ê°ê° ë…ë¦½ ì‘ì—…ìœ¼ë¡œ ì²˜ë¦¬)
2. **ìë™ ë²ˆì—­**: ë¡œì»¬ ì›Œì»¤ê°€ ë²ˆì—­ ìˆ˜í–‰
3. **ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**: ì™„ë£Œë˜ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ

### íŠ¹ì§•
- âœ… ê° íŒŒì¼ì€ ë…ë¦½ì ì¸ ì‘ì—…ìœ¼ë¡œ ì²˜ë¦¬
- âœ… í•œ íŒŒì¼ì´ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ íŒŒì¼ì— ì˜í–¥ ì—†ìŒ
- âœ… ìë™ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ì§„í–‰ ìƒí™© í™•ì¸
    """)

# Drive ì—°ê²°
drive = get_drive_service()
folders = get_subfolder_ids(drive)

st.success("âœ… Google Drive ì—°ê²°ë¨")
st.caption(f"ê³µìœ  í´ë”: `{DXF_SHARED_FOLDER_ID}`")

# =========================
# Sidebar
# =========================
st.sidebar.header("âš™ï¸ ì˜µì…˜")
auto_refresh = st.sidebar.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨", value=True)
refresh_sec = st.sidebar.slider("ìƒˆë¡œê³ ì¹¨ ì£¼ê¸°(ì´ˆ)", 3, 30, 5)

st.sidebar.divider()
st.sidebar.caption("ğŸ“ í´ë” ID")
for name in SUBFOLDERS:
    st.sidebar.write(f"- {name}: `{folders[name][:12]}...`")

# =========================
# 1) íŒŒì¼ ì—…ë¡œë“œ
# =========================
st.subheader("1ï¸âƒ£ DXF íŒŒì¼ ì—…ë¡œë“œ")

uploaded_files = st.file_uploader(
    "DXF íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)",
    type=["dxf"],
    accept_multiple_files=True,
    help="ê° íŒŒì¼ì€ ë…ë¦½ì ì¸ ì‘ì—…ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤"
)

if uploaded_files:
    total_count = len(uploaded_files)
    total_size = sum(f.size for f in uploaded_files)
    
    st.write(f"**ì„ íƒëœ íŒŒì¼**: {total_count}ê°œ | **ì´ í¬ê¸°**: {format_bytes(total_size)}")
    
    # í¬ê¸° ì²´í¬
    oversized = [f for f in uploaded_files if f.size > MAX_FILE_BYTES]
    
    if oversized:
        st.error(f"âŒ ë‹¤ìŒ íŒŒì¼ì´ {MAX_FILE_MB}MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤:")
        for f in oversized:
            st.write(f"  - {f.name} ({format_bytes(f.size)})")
    else:
        # ì—…ë¡œë“œ ë²„íŠ¼
        if st.button("ğŸ“¤ ì—…ë¡œë“œ ì‹œì‘", type="primary"):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            uploaded_jobs = []
            failed_jobs = []
            created_at = now_seoul_iso()
            
            with st.spinner("ì—…ë¡œë“œ ì¤‘..."):
                for idx, uploaded_file in enumerate(uploaded_files, 1):
                    try:
                        # íŒŒì¼ëª… ì •ë¦¬
                        safe_name = sanitize_filename(uploaded_file.name)
                        file_bytes = uploaded_file.getvalue()
                        
                        # job_id ìƒì„±
                        job_id = make_job_id(safe_name)
                        
                        # INBOX íŒŒì¼ëª…: job_id__ì›ë³¸ëª….dxf
                        inbox_name = f"{job_id}__{safe_name}"
                        
                        # META íŒŒì¼ëª…: job_id.json
                        meta_filename = f"{job_id}.json"
                        
                        status_text.text(f"[{idx}/{total_count}] {safe_name} ì—…ë¡œë“œ ì¤‘...")
                        
                        # 1) INBOXì— DXF ì—…ë¡œë“œ
                        inbox_resp = upload_file_to_inbox(
                            drive,
                            folders["INBOX"],
                            inbox_name,
                            file_bytes
                        )
                        
                        # 2) META JSON ìƒì„±
                        meta_payload = {
                            "job_id": job_id,
                            "original_name": safe_name,
                            "inbox_name": inbox_name,
                            "inbox_file_id": inbox_resp.get("id"),
                            "status": "queued",
                            "progress": 0,
                            "message": "Uploaded to INBOX. Waiting for worker.",
                            "created_at": created_at,
                            "updated_at": now_seoul_iso(),
                            "done_file": None,
                            "error": None,
                        }
                        
                        create_meta_json(
                            drive,
                            folders["META"],
                            meta_filename,
                            meta_payload
                        )
                        
                        uploaded_jobs.append({
                            "job_id": job_id,
                            "original_name": safe_name,
                        })
                        
                    except Exception as e:
                        failed_jobs.append({
                            "file": uploaded_file.name,
                            "error": str(e)
                        })
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    progress = int((idx / total_count) * 100)
                    progress_bar.progress(progress)
            
            # ê²°ê³¼ í‘œì‹œ
            st.success(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {len(uploaded_jobs)}ê°œ")
            
            if failed_jobs:
                st.error(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {len(failed_jobs)}ê°œ")
                for fail in failed_jobs:
                    st.write(f"  - {fail['file']}: {fail['error']}")
            
            # ì—…ë¡œë“œëœ job_id í‘œì‹œ
            if uploaded_jobs:
                st.write("**ìƒì„±ëœ ì‘ì—…:**")
                for job in uploaded_jobs:
                    st.code(f"{job['job_id']} ({job['original_name']})")
                
                # ì„¸ì…˜ì— ë§ˆì§€ë§‰ ì—…ë¡œë“œ job ì €ì¥ (ì„ íƒ í¸ì˜)
                st.session_state["last_uploaded_job"] = uploaded_jobs[-1]["job_id"]

# =========================
# 2) ì‘ì—… ëª¨ë‹ˆí„°ë§
# =========================
st.subheader("2ï¸âƒ£ ì‘ì—… ìƒíƒœ í™•ì¸")

# ìµœê·¼ ì‘ì—… ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
recent_jobs = list_recent_jobs(drive, folders["META"], limit=30)
job_ids = [f["name"].replace(".json", "") for f in recent_jobs]

# ê¸°ë³¸ ì„ íƒ: ë§ˆì§€ë§‰ ì—…ë¡œë“œí•œ job
default_job = st.session_state.get("last_uploaded_job")
default_index = 0
if default_job and default_job in job_ids:
    default_index = job_ids.index(default_job)

selected_job = None
if job_ids:
    selected_job = st.selectbox(
        "ì‘ì—… ì„ íƒ",
        job_ids,
        index=default_index,
        help="ìµœê·¼ 30ê°œ ì‘ì—… í‘œì‹œ"
    )
else:
    st.info("ğŸ“­ ì•„ì§ ì—…ë¡œë“œëœ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")

# ìë™ ìƒˆë¡œê³ ì¹¨
if auto_refresh:
    try:
        from streamlit_autorefresh import st_autorefresh
        st_autorefresh(interval=refresh_sec * 1000, key="auto_refresh")
    except ImportError:
        pass

# ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
col1, col2 = st.columns([1, 3])
with col1:
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

# ì„ íƒëœ ì‘ì—… ìƒì„¸ ì •ë³´
if selected_job:
    meta_filename = f"{selected_job}.json"
    meta = read_meta_json(drive, folders["META"], meta_filename)
    
    if meta:
        status = meta.get("status", "unknown")
        progress = int(meta.get("progress", 0) or 0)
        message = meta.get("message", "")
        
        # ìƒíƒœ í‘œì‹œ
        st.write(f"**ìƒíƒœ**: `{status}`")
        st.write(f"**ë©”ì‹œì§€**: {message}")
        st.write(f"**ì—…ë°ì´íŠ¸**: {meta.get('updated_at', 'N/A')}")
        
        # ì§„í–‰ë¥  ë°”
        st.progress(min(max(progress, 0), 100) / 100.0)
        
        # ì—ëŸ¬ í‘œì‹œ
        if status == "error":
            st.error("âŒ ì‘ì—… ì‹¤íŒ¨")
            if meta.get("error"):
                with st.expander("ì—ëŸ¬ ìƒì„¸"):
                    st.code(meta.get("error"))
        
        # ì™„ë£Œ ì‹œ ë‹¤ìš´ë¡œë“œ
        if status == "done":
            done_file = meta.get("done_file")
            
            if not done_file:
                st.warning("âš ï¸ ì™„ë£Œ ìƒíƒœì´ì§€ë§Œ done_file ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success("âœ… ë²ˆì—­ ì™„ë£Œ!")
                st.write(f"**ê²°ê³¼ íŒŒì¼**: `{done_file}`")
                
                # DONE í´ë”ì—ì„œ íŒŒì¼ ì°¾ê¸°
                done_obj = find_done_file(drive, folders["DONE"], done_file)
                
                if not done_obj:
                    st.warning("âš ï¸ ê²°ê³¼ íŒŒì¼ì„ DONE í´ë”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                else:
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    with st.spinner("ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì¤‘..."):
                        try:
                            file_data = download_file_bytes(drive, done_obj["id"])
                            
                            st.download_button(
                                label="ğŸ“¥ ê²°ê³¼ DXF ë‹¤ìš´ë¡œë“œ",
                                data=file_data,
                                file_name=done_file,
                                mime="application/dxf",
                                type="primary",
                            )
                        except Exception as e:
                            st.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    else:
        st.info("ğŸ“„ ì„ íƒí•œ ì‘ì—…ì˜ ë©”íƒ€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
